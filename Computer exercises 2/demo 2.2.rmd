---
title: "Demo 2.2"
author: "Nguyen Xuan Binh"
date: "11/12/2021"
output:
  word_document: default
  html_document: default
---

When cement hardens, heat is produced. The amount of heat depends on the composition of the cement. From file hald.txt, you can find the following information regarding 13 different batches of cement:
HEAT =heat energy (cal/g)
CHEM1, CHEM2, CHEM3, CHEM4 =ingredients of cement (% of the dry substance)

Solution. The goal of the exercise is to find out which of the explanatory variables CHEM1, CHEM2, CHEM3, CHEM4 are significant in explaining the behavior of the response variable HEAT.
First, we import the data and install the package car for later use.


install.packages("car")
```{r}
library(car)
```

**a) Estimate a linear regression model with all explanatory variables. Compare statistical significance of the regression coefficients and examine the variance inflation factors of the corresponding explanatory variables.**

Estimation of the full model
In situations, where it is not known which of the explanatory variables affect the
response variable, it is first usually reasonable to estimate the full model, i.e. the
model with all candidates for explanatory variables.
First, we should examine the correlations between the different variables.

```{r}
hald=read.table("hald.txt",header=T)
cor(hald)
```
The variable HEAT correlates strongly with all explanatory candidates. Correlation is positive with the variables CHEM1 and CHEM2, and negative with CHEM3 and CHEM4. There is a strong negative correlation between variables CHEM1 and CHEM3, as well as between variables CHEM2 and CHEM4. We begin by estimating the full model:

HEAT = β0 + β1CHEM1 + β2CHEM2 + β3CHEM3 + β4CHEM4 + ε (1)

```{r}
fullmodel=lm(HEAT~CHEM1+CHEM2+CHEM3+CHEM4,data=hald)
summary(fullmodel)
```

The model (1) has a high coefficient of determination (98.2%). The value of the
F-test statistics for the null hypothesis
H0 : β1 = β2 = β3 = β4 = 0
is 111.5 and the p-value is close to zero, i.e. the model is statistically significant and at least one of the regression coefficients β0; β1; β2; β3 deviates from zero.
However, none of the explanatory variables of the model (1) is statistically significant with a 5%:n level of significance. This is due to the multicollinearity of the explanatory variables.
Multicollinearity of the explanatory variables can be measured with VIF-coefficients. The VIF-coefficient is 1 for an explanatory variable whose sample correlation is 0 with other explanatory variables. The stronger a variable is linearly dependent on the other variables, the larger the VIF-coefficient of the variable is. If
VIF > 10;
then multicollinearity might be a problem.
VIF-coefficients can be computed with the function vif of the package car.

```{r}
vif(fullmodel)
```

In model (1), the VIF-coefficients of the variables CHEM2 and CHEM4 are larger
than 200, which indicates that strong multicollinearity is present in the model.
Next, we further study the existing multicollinearity by estimating two regression
models, where CHEM2 and CHEM4 are explained with all the other explanatory
variables of the original model (1).
Consider the model:
CHEM2 = α0 + α1CHEM1 + α3CHEM3 + α4CHEM4 + δ; (2)
which can be estimated using,
```{r}
model2 <- lm(CHEM2 ~ CHEM1+CHEM3+CHEM4,data=hald)
summary(model2)
```
The coefficient of determination of the model is 99.6% implying that CHEM2 is
strongly linearly dependent on the other explanatory variables. Note that the VIFcoefficient of CHEM2 in the model (1) is
VIF2 = 1/(1 − R2^2);
where R2^2 is the coefficient of determination for model (2).
Consider the model,
CHEM4 = α0 + α1CHEM1 + α2CHEM2 + α3CHEM3 + δ; (3)
which can be estimated using,

```{r}
formula <- lm(CHEM4 ~ CHEM1+CHEM2+CHEM3,data=hald)
summary(formula)
```
The coefficient of determination of the model is 99.7% implying that CHEM4 is
strongly linearly dependent on the other explanatory variables.
Note that the VIF-coefficient of CHEM4 in the model (1) is
VIF4 = 1/(1 − R3^2);
where R3^2 is the coefficient of determination of the model (3).
Multicollinearity of the model (1) is explained by noting that cement consists almost entirely of the substances CHEM1, CHEM2, CHEM3 and CHEM4. The sum of these
variables is somewhere between 95-99%. Therefore, by increasing the amount of a substance, we have to reduce the amount of some other substances in the mixture.
This explains the strong negative correlations between the variable pairs (CHEM1, CHEM3) and (CHEM2, CHEM4).

**b) Find the best combination of explanatory variables by using Akaike information criterion (AIC).**

There exists different strategies for choosing the explanatory variables of a regression model. When searching for the best combination of explanatory variables, different models are compared to each other by using some criterion for model selection.
Some well-known criteria for model selection are, e.g., Akaike information criterion (AIC), Schwarz bayesian information criterion (SBIC) and Hannan-Quinn criterion (HQ).
The criterion functions of model selection methods are of the form,
min M⊆(1,....,q) C(|M|; (σM^)^2 ),
where M is a combination of explanatory variables and (σ|M|^)^2 is the maximum likelihood estimator for the variance of the residuals of the corresponding model. Furthermore, C is an increasing function with respect to the two arguments. In general, we expect the following from a criterion function:
• Maximal coefficient of determination,
• Using as few explanatory variables as possible.
In R, the function step() gives the combination of explanatory variables that minimizes the value of AIC. Note that step() computes AIC by assuming normally
distributed residuals.

```{r}
step(fullmodel)
```
The output can be interpreted as follows. The AIC of the full model is 26.944. When CHEM3 is omitted from the model, the AIC is 24.974. When CHEM4 is omitted,
the AIC is 25.011. When CHEM2 is omitted, the AIC is 25.728 and when CHEM1
is omitted, the AIC is 30.576. We wish to minimize the model selection criterion and hence, we estimate the model without CHEM3.
Consider the model,
HEAT = β0 + β1CHEM1 + β2CHEM2 + β4CHEM4: (4)
Now the AIC of model (4) is 24.974. From the output of R, we see that omitting any
of the remaining explanatory variables (CHEM1, CHEM2, CHEM4) would increase
the AIC value. Next, we estimate the model (4)
```{r}
model4 <- lm(HEAT ~ CHEM1 + CHEM2 + CHEM4 , data=hald)
summary(model4)
```
Note that the variables CHEM2 and CHEM4 are not statistically significant with 5%
significance level. Figure 5 illustrates the estimated residuals of the full model. The shape of the histogram indicates that the normality assumption does not hold, which on the other hand means that AIC is not a reliable method for model selection. In homework assignment 2.3, the model selection is done using the permutation test. The permutation test does not require normality and thus, it is the safer alternative here.

Remark: It is not possible to use the error sum of squares or the coefficient of
determination as a criterion for model selection, since minimizing the error sum of squares as well as maximizing the coefficient of determination always leads to the full model (the model with all possible explanatory variables).